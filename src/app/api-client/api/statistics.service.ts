/**
 * FastAPI
 *
 *
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */
/* tslint:disable:no-unused-variable member-ordering */

import { Inject, Injectable, Optional } from '@angular/core';
import {
  HttpClient,
  HttpHeaders,
  HttpParams,
  HttpResponse,
  HttpEvent,
  HttpParameterCodec,
  HttpContext,
} from '@angular/common/http';
import { CustomHttpParameterCodec } from '../encoder';
import { Observable } from 'rxjs';

// @ts-ignore
import { CategoryStatistics } from '../model/categoryStatistics';
// @ts-ignore
import { ErrorResponse } from '../model/errorResponse';
// @ts-ignore
import { HTTPValidationError } from '../model/hTTPValidationError';
// @ts-ignore
import { MODEL_REFERENCE_CATEGORY } from '../model/mODELREFERENCECATEGORY';

// @ts-ignore
import { BASE_PATH, COLLECTION_FORMATS } from '../variables';
import { Configuration } from '../configuration';
import { BaseService } from '../api.base.service';

@Injectable({
  providedIn: 'root',
})
export class StatisticsService extends BaseService {
  constructor(
    protected httpClient: HttpClient,
    @Optional() @Inject(BASE_PATH) basePath: string | string[],
    @Optional() configuration?: Configuration,
  ) {
    super(basePath, configuration);
  }

  /**
   * Get models merged with AI Horde runtime statistics
   * Get AI Horde statistics data for models in a given category.  Combines live runtime statistics from the AI Horde API: - Worker count, queued jobs, performance metrics, ETA - Usage statistics (day, month, total) - Optional worker details  **Caching:** - Model reference data: cached by ModelReferenceManager (60s TTL) - Horde API data: cached by HordeAPIIntegration (60s TTL, Redis if available) - Merged results: computed on-demand (no caching)  Args:     model_category_name: The model category (image_generation or text_generation).     manager: Model reference manager dependency.     horde_api: Horde API integration dependency.     include_workers: Include detailed worker information for each model.     min_worker_count: Filter to models with at least this many workers.     sort_by: Sort by field (worker_count, usage_total, usage_month, name).     sort_desc: Sort in descending order (default: True).  Returns:     JSONResponse: Dict of model_name -&gt; enriched_model_data.  Raises:     HTTPException: 404 if category not found, 500 if Horde API fails.
   * @param modelCategoryName
   * @param includeWorkers
   * @param minWorkerCount
   * @param sortBy
   * @param sortDesc
   * @param observe set whether or not to return the data Observable as the body, response or events. defaults to returning the body.
   * @param reportProgress flag to report request and response progress.
   */
  public readModelsWithStats(
    modelCategoryName: MODEL_REFERENCE_CATEGORY,
    includeWorkers?: boolean,
    minWorkerCount?: number,
    sortBy?: string,
    sortDesc?: boolean,
    observe?: 'body',
    reportProgress?: boolean,
    options?: {
      httpHeaderAccept?: 'application/json';
      context?: HttpContext;
      transferCache?: boolean;
    },
  ): Observable<{ [key: string]: any }>;
  public readModelsWithStats(
    modelCategoryName: MODEL_REFERENCE_CATEGORY,
    includeWorkers?: boolean,
    minWorkerCount?: number,
    sortBy?: string,
    sortDesc?: boolean,
    observe?: 'response',
    reportProgress?: boolean,
    options?: {
      httpHeaderAccept?: 'application/json';
      context?: HttpContext;
      transferCache?: boolean;
    },
  ): Observable<HttpResponse<{ [key: string]: any }>>;
  public readModelsWithStats(
    modelCategoryName: MODEL_REFERENCE_CATEGORY,
    includeWorkers?: boolean,
    minWorkerCount?: number,
    sortBy?: string,
    sortDesc?: boolean,
    observe?: 'events',
    reportProgress?: boolean,
    options?: {
      httpHeaderAccept?: 'application/json';
      context?: HttpContext;
      transferCache?: boolean;
    },
  ): Observable<HttpEvent<{ [key: string]: any }>>;
  public readModelsWithStats(
    modelCategoryName: MODEL_REFERENCE_CATEGORY,
    includeWorkers?: boolean,
    minWorkerCount?: number,
    sortBy?: string,
    sortDesc?: boolean,
    observe: any = 'body',
    reportProgress: boolean = false,
    options?: {
      httpHeaderAccept?: 'application/json';
      context?: HttpContext;
      transferCache?: boolean;
    },
  ): Observable<any> {
    if (modelCategoryName === null || modelCategoryName === undefined) {
      throw new Error(
        'Required parameter modelCategoryName was null or undefined when calling readModelsWithStats.',
      );
    }

    let localVarQueryParameters = new HttpParams({ encoder: this.encoder });
    localVarQueryParameters = this.addToHttpParams(
      localVarQueryParameters,
      <any>includeWorkers,
      'include_workers',
    );
    localVarQueryParameters = this.addToHttpParams(
      localVarQueryParameters,
      <any>minWorkerCount,
      'min_worker_count',
    );
    localVarQueryParameters = this.addToHttpParams(localVarQueryParameters, <any>sortBy, 'sort_by');
    localVarQueryParameters = this.addToHttpParams(
      localVarQueryParameters,
      <any>sortDesc,
      'sort_desc',
    );

    let localVarHeaders = this.defaultHeaders;

    const localVarHttpHeaderAcceptSelected: string | undefined =
      options?.httpHeaderAccept ?? this.configuration.selectHeaderAccept(['application/json']);
    if (localVarHttpHeaderAcceptSelected !== undefined) {
      localVarHeaders = localVarHeaders.set('Accept', localVarHttpHeaderAcceptSelected);
    }

    const localVarHttpContext: HttpContext = options?.context ?? new HttpContext();

    const localVarTransferCache: boolean = options?.transferCache ?? true;

    let responseType_: 'text' | 'json' | 'blob' = 'json';
    if (localVarHttpHeaderAcceptSelected) {
      if (localVarHttpHeaderAcceptSelected.startsWith('text')) {
        responseType_ = 'text';
      } else if (this.configuration.isJsonMime(localVarHttpHeaderAcceptSelected)) {
        responseType_ = 'json';
      } else {
        responseType_ = 'blob';
      }
    }

    let localVarPath = `/model_references/statistics/${this.configuration.encodeParam({ name: 'modelCategoryName', value: modelCategoryName, in: 'path', style: 'simple', explode: false, dataType: 'MODEL_REFERENCE_CATEGORY', dataFormat: undefined })}/with-stats`;
    const { basePath, withCredentials } = this.configuration;
    return this.httpClient.request<{ [key: string]: any }>('get', `${basePath}${localVarPath}`, {
      context: localVarHttpContext,
      params: localVarQueryParameters,
      responseType: <any>responseType_,
      ...(withCredentials ? { withCredentials } : {}),
      headers: localVarHeaders,
      observe: observe,
      transferCache: localVarTransferCache,
      reportProgress: reportProgress,
    });
  }

  /**
   * Get statistics for a model category
   * Get comprehensive statistics for a model reference category.  Returns aggregate metrics including: - Total model counts (overall, NSFW, SFW) - Baseline distribution - Download statistics - Tag and style distributions - Category-specific metrics (trigger words, inpainting, etc.)  Statistics are cached with TTL (default 300s) and automatically invalidated when model data changes. Caching is skipped when grouping is enabled.  Args:     model_category_name: The model reference category to get statistics for.     manager: The model reference manager (injected).     stats_cache: The statistics cache (injected).     group_text_models: Group text models by base name (strips quantization info).     limit: Maximum number of models to return (for pagination).     offset: Number of models to skip (for pagination).  Returns:     CategoryStatistics containing all computed metrics.  Raises:     HTTPException: 404 if category not found, 500 if computation fails.
   * @param modelCategoryName
   * @param groupTextModels Group text models by base name (strips quantization)
   * @param limit Maximum number of models to return (None &#x3D; all)
   * @param offset Number of models to skip (for pagination)
   * @param observe set whether or not to return the data Observable as the body, response or events. defaults to returning the body.
   * @param reportProgress flag to report request and response progress.
   */
  public readV2CategoryStatistics(
    modelCategoryName: MODEL_REFERENCE_CATEGORY,
    groupTextModels?: boolean,
    limit?: number,
    offset?: number,
    observe?: 'body',
    reportProgress?: boolean,
    options?: {
      httpHeaderAccept?: 'application/json';
      context?: HttpContext;
      transferCache?: boolean;
    },
  ): Observable<CategoryStatistics>;
  public readV2CategoryStatistics(
    modelCategoryName: MODEL_REFERENCE_CATEGORY,
    groupTextModels?: boolean,
    limit?: number,
    offset?: number,
    observe?: 'response',
    reportProgress?: boolean,
    options?: {
      httpHeaderAccept?: 'application/json';
      context?: HttpContext;
      transferCache?: boolean;
    },
  ): Observable<HttpResponse<CategoryStatistics>>;
  public readV2CategoryStatistics(
    modelCategoryName: MODEL_REFERENCE_CATEGORY,
    groupTextModels?: boolean,
    limit?: number,
    offset?: number,
    observe?: 'events',
    reportProgress?: boolean,
    options?: {
      httpHeaderAccept?: 'application/json';
      context?: HttpContext;
      transferCache?: boolean;
    },
  ): Observable<HttpEvent<CategoryStatistics>>;
  public readV2CategoryStatistics(
    modelCategoryName: MODEL_REFERENCE_CATEGORY,
    groupTextModels?: boolean,
    limit?: number,
    offset?: number,
    observe: any = 'body',
    reportProgress: boolean = false,
    options?: {
      httpHeaderAccept?: 'application/json';
      context?: HttpContext;
      transferCache?: boolean;
    },
  ): Observable<any> {
    if (modelCategoryName === null || modelCategoryName === undefined) {
      throw new Error(
        'Required parameter modelCategoryName was null or undefined when calling readV2CategoryStatistics.',
      );
    }

    let localVarQueryParameters = new HttpParams({ encoder: this.encoder });
    localVarQueryParameters = this.addToHttpParams(
      localVarQueryParameters,
      <any>groupTextModels,
      'group_text_models',
    );
    localVarQueryParameters = this.addToHttpParams(localVarQueryParameters, <any>limit, 'limit');
    localVarQueryParameters = this.addToHttpParams(localVarQueryParameters, <any>offset, 'offset');

    let localVarHeaders = this.defaultHeaders;

    const localVarHttpHeaderAcceptSelected: string | undefined =
      options?.httpHeaderAccept ?? this.configuration.selectHeaderAccept(['application/json']);
    if (localVarHttpHeaderAcceptSelected !== undefined) {
      localVarHeaders = localVarHeaders.set('Accept', localVarHttpHeaderAcceptSelected);
    }

    const localVarHttpContext: HttpContext = options?.context ?? new HttpContext();

    const localVarTransferCache: boolean = options?.transferCache ?? true;

    let responseType_: 'text' | 'json' | 'blob' = 'json';
    if (localVarHttpHeaderAcceptSelected) {
      if (localVarHttpHeaderAcceptSelected.startsWith('text')) {
        responseType_ = 'text';
      } else if (this.configuration.isJsonMime(localVarHttpHeaderAcceptSelected)) {
        responseType_ = 'json';
      } else {
        responseType_ = 'blob';
      }
    }

    let localVarPath = `/model_references/statistics/${this.configuration.encodeParam({ name: 'modelCategoryName', value: modelCategoryName, in: 'path', style: 'simple', explode: false, dataType: 'MODEL_REFERENCE_CATEGORY', dataFormat: undefined })}`;
    const { basePath, withCredentials } = this.configuration;
    return this.httpClient.request<CategoryStatistics>('get', `${basePath}${localVarPath}`, {
      context: localVarHttpContext,
      params: localVarQueryParameters,
      responseType: <any>responseType_,
      ...(withCredentials ? { withCredentials } : {}),
      headers: localVarHeaders,
      observe: observe,
      transferCache: localVarTransferCache,
      reportProgress: reportProgress,
    });
  }
}
